{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project Notebook",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQlxyaOpUm0C"
      },
      "source": [
        "# INET4061 Final Project Notebook\n",
        "11/18/21\n",
        "\n",
        "Adam Levy, Jeevan Prakash, Tyler Perkins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt61vhE-nmxu"
      },
      "source": [
        "# Overview\n",
        "\n",
        "In this notebook, we will train models to recognize digits from a dataset of hand-written digits called MNIST (\"Modified National Institute of Standards and Technology\") which has been used for benchmarking image classifiers. One potential business application of algorithmic identification of handwritten writing is the automatic digitization of handwritten documents. A model which can recognize human handwriting could be used to create a program that takes handwritten documents as input and returns a digitized document such as a PDF as output. There are many applications for this technology, such as converting student handwriting on exams to a digital format so that answers can be more easily read and graded by the proctor. MNIST is known as a \"hello world\" dataset because it's very basic. Each image is 28 by 28 pixels, represented in the data by 784 columns (one for each pixel) holding a value of 0 to 255 to represent darkness of the pixel, with higher values being darker. The dataset has 60,000 data points for the training set and 10,000 for the testing set. We will execute three models (KNN, SVM, and CNN) on this dataset and see which one performs the \"best.\" To determine this, we will measure the accuracy of the model, or the number of digits it correctly identified over the total number of digits in the dataset.\n",
        "\n",
        "##KNN:\n",
        "KNN is a classification algorithm known for its quick calculation time and predictive power. The algorithm will consider \"K\" of a particular instance's nearest neighbors. Each of the neighbors have one vote. The instance in question is classified as whatever the majority of the neighbors are. Thus, if instance X has K=5, and the five neighbors are 3 A and 2 B, then the majority of these neighbors are A, and so instance X is classified as type A.\n",
        "\n",
        "##SVM:\n",
        "Support vector machines (SVMs) are particular linear classifiers which are based on the margin maximization principle. They perform structural risk minimization, which improves the complexity of the classifier with the aim of achieving excellent generalization performance. The SVM accomplishes the classification task by constructing, in a higher dimensional space, the hyperplane that optimally separates the data into two categories.\n",
        "\n",
        "##CNN:\n",
        "Convolutional Neural Networks (CNN) are feed forward artificial neural networks. They are highly acclaimed for their performance in computer vision tasks. CNN was based on the visual cortex found in animals. CNN is made up of an input layer, hidden layers, and an output layer. The hidden layers include layers that perform convolutions. A convolution kernal slides along the input layer which creates a feature map. This feature map is then passed into the next layer. There are also pooling layers to reduce the dimensions of the data along the network.\n",
        "\n",
        "\n",
        "##Sources\n",
        "https://www.kaggle.com/c/digit-recognizer/data?select=train.csv\n",
        "\n",
        "https://www.askpython.com/python/examples/load-and-plot-mnist-dataset-in-python\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "\n",
        "https://medium.com/@pushkarmandot/what-is-the-significance-of-c-value-in-support-vector-machine-28224e852c5a\n",
        "\n",
        "https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-73003-5_299\n",
        "\n",
        "https://analyticsindiamag.com/convolutional-neural-network-image-classification-overview/\n",
        "\n",
        "https://en.wikipedia.org/wiki/Convolutional_neural_network\n",
        "\n",
        "https://androidkt.com/get-the-roc-curve-and-auc-for-keras-model/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBnFqtjk2Vss"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IoRxXG22cU3",
        "outputId": "4bb16ca6-adee-4e36-cdca-5e9b58b4a76b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using matplotlib backend: agg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4LFqyJzUfK6"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHC6FQbVpdqp"
      },
      "source": [
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPszyCz_uPN5",
        "outputId": "a0b75d08-01ee-452e-a398-81630224b6d6"
      },
      "source": [
        "print(\"\\n---\\nX Train Data\\n---\\n\")\n",
        "print(train_X)\n",
        "print(\"\\n---\\nY Train Data\\n---\\n\")\n",
        "print(train_y)\n",
        "print(\"\\n---\\nX Test Data\\n---\\n\")\n",
        "print(test_X)\n",
        "print(\"\\n---\\nY Test Data\\n---\\n\")\n",
        "print(test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "X Train Data\n",
            "---\n",
            "\n",
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n",
            "\n",
            "---\n",
            "Y Train Data\n",
            "---\n",
            "\n",
            "[5 0 4 ... 5 6 8]\n",
            "\n",
            "---\n",
            "X Test Data\n",
            "---\n",
            "\n",
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n",
            "\n",
            "---\n",
            "Y Test Data\n",
            "---\n",
            "\n",
            "[7 2 1 ... 4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyTGteavp0Bg"
      },
      "source": [
        "#Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0lnG_8juZRT",
        "outputId": "dac74245-ccb3-4f70-9080-054dd0f133b1"
      },
      "source": [
        "print(\"---\\nX Train Data Shape\\n---\")\n",
        "print(train_X.shape)\n",
        "print(\"---\\nY Train Data Shape\\n---\")\n",
        "print(train_y.shape)\n",
        "print(\"---\\nX Test Data Shape\\n---\")\n",
        "print(test_X.shape)\n",
        "print(\"---\\nY Test Data Shape\\n---\")\n",
        "print(test_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "X Train Data Shape\n",
            "---\n",
            "(60000, 28, 28)\n",
            "---\n",
            "Y Train Data Shape\n",
            "---\n",
            "(60000,)\n",
            "---\n",
            "X Test Data Shape\n",
            "---\n",
            "(10000, 28, 28)\n",
            "---\n",
            "Y Test Data Shape\n",
            "---\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZxMVJdHwj3G"
      },
      "source": [
        "Because we are expecting the shape of our images is 28x28 pixels, we are sure from this result that we are not missing any pixels and our data is well-formed given that our arrays are immutable, so there cannot be any null values. There are 60,000 train images with 28x28 pixels (train_X) and 60,000 resulting digits after the images have been classified (train_Y). Then there are 10,000 images to compare our models against. Now let's check that our pixel values are within an expected range:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM4310GvugL9",
        "outputId": "376d1957-e7d4-47e9-b998-2c41dd659336"
      },
      "source": [
        "print(\"The max and min of the train_X data are: \" + str(train_X.max()) + \" and \" + str(train_X.min()))\n",
        "print(\"The max and min of the train_y data are: \" + str(train_y.max()) + \" and \" + str(train_y.min()))\n",
        "print(\"The max and min of the test_X data are: \" + str(test_X.max()) + \" and \" + str(train_X.min()))\n",
        "print(\"The max and min of the test_y data are: \" + str(test_y.max()) + \" and \" + str(train_y.min()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max and min of the train_X data are: 255 and 0\n",
            "The max and min of the train_y data are: 9 and 0\n",
            "The max and min of the test_X data are: 255 and 0\n",
            "The max and min of the test_y data are: 9 and 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT_CWiZzzPYS"
      },
      "source": [
        "Therefore our values are within the expected bounds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "5R6kl36Lp2Yo",
        "outputId": "326ebbf3-45c6-4764-a001-a93db2d03f8c"
      },
      "source": [
        "for i in range(9):\n",
        " plt.subplot(3,3,i+1)\n",
        " plt.imshow(train_X[i], cmap=plt.get_cmap('gray'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCdtT5Ezzc9x"
      },
      "source": [
        "Above are examples of what an image in our dataset looks like. Now let's flatten the pixel data arrays so that we can run our models on them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gViikeqAAEUj"
      },
      "source": [
        "train_X_flat = []\n",
        "for i in range(len(train_X)):\n",
        "  train_X_flat.append(train_X[i].flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ye5YtyNBuvV"
      },
      "source": [
        "test_X_flat = []\n",
        "for i in range(len(test_X)):\n",
        "  test_X_flat.append(test_X[i].flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFW_qMzIFYLm"
      },
      "source": [
        "#Model Selection\n",
        "\n",
        "We will comparing three classification models: Convolutional Neural Networks (CNN), Support Vector Machines (SVM), and K-Nearest Neighbors (KNN). With the data that we gather, we will measure their accuracy and determine the best performing model to be the one with the greatest accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w01tQyJ8PK5e"
      },
      "source": [
        "##1. K-Nearest Neighbors\n",
        "\n",
        "Source: https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_knn_algorithm_finding_nearest_neighbors.htm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_6UF9KzqYT_"
      },
      "source": [
        "We will create a new KNN classifier, setting n-neighbors to 10. If 6 out of 10 nearest neighbors are classified as digit \"2\", then this datapoint will also be classified as digit \"2\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo4FzPwFpYa4",
        "outputId": "f2a51fc5-1e11-4e1b-bd07-b22efa54fb2d"
      },
      "source": [
        "#Training Model\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors = 10)\n",
        "classifier.fit(train_X_flat, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=10)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwp1DnujqmLy"
      },
      "source": [
        "The predict function makes predictions on test data and stores the result as an array, where each element represents a predicted digit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcAsykNxqJoR"
      },
      "source": [
        "#Prediction\n",
        "\n",
        "y_pred = classifier.predict(test_X_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UhzjgzZqqwN",
        "outputId": "8544e758-1f5c-4da2-8da2-36f103cdf03c"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 2 1 ... 4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA9V-Z9croJ_"
      },
      "source": [
        "The predict function makes predictions on test data. The confusion matrix here shows how many digits got classified as each type of digit. For example, digit 0 was classified as \"0\" 972 times, never as \"1\", thirteen times as digit \"2\", and never as digit \"3\". Digit \"1\" was classified as as \"0\" once, as digit \"1\" 1132 times, and as digit \"2\" twelve times. The precision for each digit remained between 0.95 and 0.99, and recall between 0.95 and 1.00. The important information that we gain from this calculation is the accuracy: it is determined to be 0.9665, or 96.65%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bewxTeCaqLyS",
        "outputId": "f9d68c14-d5b2-4916-bd13-6d1ec56c4abb"
      },
      "source": [
        "#Print Results\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "result = confusion_matrix(test_y, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(result)\n",
        "\n",
        "result1 = classification_report(test_y, y_pred)\n",
        "print(\"Classification Report:\",)\n",
        "print(result1)\n",
        "\n",
        "result2 = accuracy_score(test_y,y_pred)\n",
        "print(\"Accuracy:\",result2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[ 972    1    1    0    0    2    3    1    0    0]\n",
            " [   0 1132    2    0    0    0    1    0    0    0]\n",
            " [  13   12  982    2    1    0    2   17    3    0]\n",
            " [   0    3    3  976    1   10    1    7    6    3]\n",
            " [   2   11    0    0  940    0    4    1    1   23]\n",
            " [   4    0    0   12    1  863    6    1    1    4]\n",
            " [   6    4    0    0    3    2  943    0    0    0]\n",
            " [   0   27    4    0    2    0    0  983    0   12]\n",
            " [   6    4    5   11    7    9    4    7  914    7]\n",
            " [   7    6    3    7   10    3    1   10    2  960]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98       980\n",
            "           1       0.94      1.00      0.97      1135\n",
            "           2       0.98      0.95      0.97      1032\n",
            "           3       0.97      0.97      0.97      1010\n",
            "           4       0.97      0.96      0.97       982\n",
            "           5       0.97      0.97      0.97       892\n",
            "           6       0.98      0.98      0.98       958\n",
            "           7       0.96      0.96      0.96      1028\n",
            "           8       0.99      0.94      0.96       974\n",
            "           9       0.95      0.95      0.95      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n",
            "Accuracy: 0.9665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4K9ZefOzrSy"
      },
      "source": [
        "##2. Support Vector Machines\n",
        "\n",
        "Initial attempts to execute SVM on this database were unsuccessful as the model attempted to fit for hours on end. Eventually, modifications were made to the model in an attempt to reduce runtime. These include scaling the data and reducing the C paramater (which lowers the misclassification rate of the model but increases runtime) to 1/10 of its original value.\n",
        "\n",
        "Source: \n",
        "\n",
        "https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n",
        "\n",
        "\n",
        "https://datascience.stackexchange.com/questions/989/svm-using-scikit-learn-runs-endlessly-and-never-completes-execution\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkCFjvpz373Y"
      },
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "\n",
        "#Scale our data\n",
        "from sklearn import preprocessing\n",
        "train_X_scaled = preprocessing.scale(train_X_flat)\n",
        "test_X_scaled = preprocessing.scale(test_X_flat)\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear', C=0.1) # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(train_X_scaled, train_y)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "pred_y = clf.predict(test_X_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwnOgsXKB_iQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9955567b-3cca-4eca-bac1-3790c0492d34"
      },
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(test_y, pred_y))\n",
        "\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\n",
        "print(\"Precision Score : \", metrics.precision_score(test_y, pred_y, average='macro'))\n",
        "\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\n",
        "print(\"Recall Score : \", metrics.recall_score(test_y, pred_y, average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9376\n",
            "Precision Score :  0.9372256008557274\n",
            "Recall Score :  0.9365448727601307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wufgia0Hz4xU"
      },
      "source": [
        "##3. Convolutional Neural Network\n",
        "The input layer into the Convolutional Neural Network that we created uses the train_X data. The train_X data and test_X data represent the data of the images. They have been converted into numpy arrays in order to be used to create the model. train_Y represents all the actual number values of the images from the train part of the dataset.\n",
        "\n",
        "Source: https://medium.datadriveninvestor.com/my-take-at-the-mnist-dataset-97304dff2057"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdHSLVKm57e4"
      },
      "source": [
        "# categorizing the data into the 10 numbers in the dataset\n",
        "train_y_matrix = to_categorical(y = train_y, num_classes = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKXBKY6g9_Kl"
      },
      "source": [
        "In this step, I utilized the to_categorical to convert the train_y into a one-hot encoded matrix. This converts the train_y array from ``[5, 0, 4, ..., 5, 6, 8]`` format to ``[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]`` format. The one in this array represents that the first row of train_y represents the number 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUCOmRLh_G5A",
        "outputId": "3078d1bc-d06c-4608-ff13-0588753d1317"
      },
      "source": [
        "# creating shape variable (removing the first index since that is not actually part of the shape, it's actually the number of images in the training dataset)\n",
        "inputShape = np.shape(train_X)\n",
        "inputShape = (inputShape[1], inputShape[2], 1)\n",
        "inputShape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3KNS3EtCKYw"
      },
      "source": [
        "I am creating the shape variable of the train_X variable. I am removing the first index, since it is simply a count of the number of images in the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VLetKu7_xUs"
      },
      "source": [
        "# creating the actual model using sequential\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size = (5,5), activation = 'relu', input_shape = inputShape)) # convolution layer 1\n",
        "model.add(MaxPooling2D(pool_size = (2,2))) # pooling the data\n",
        "model.add(Conv2D(64, kernel_size = (5,5), activation = 'relu')) # convolution layer 2\n",
        "model.add(MaxPooling2D(pool_size = (2,2))) # pooling the data once again\n",
        "model.add(Flatten()) # flattening the data\n",
        "model.add(Dropout(0.25)) # performing drop out to regularize the data\n",
        "model.add(Dense(100, activation = 'relu')) # applying ReLu activation function to the data\n",
        "model.add(Dense(10, activation = 'softmax')) # applying softmax activation function to the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yYGivybFQss"
      },
      "source": [
        "In this step I am actually building the convolutional neural network.\n",
        "\n",
        "Steps:\n",
        "1. Add a convolution layer with 1 input layer and 32 output channels. I set the Kernel Size to be 5 by 5, which is the dimensions of the 2D convolution window. The activation function in this case is labeled as ReLu.\n",
        "2. Next, I use a 2 by 2 max pooling to reduce the spatial dimensions of the output from the previous convolution layer step\n",
        "3. Add another convolution layer with 32 input layer and 64 output channels. I also set the Kernel Size to be 5 by 5, which again is the dimensions of the 2D convolution window. The activation function in this case is once again labeled as ReLu.\n",
        "4. Next, I use a 2 by 2 max pooling again to reduce the spatial dimensions of the output from the previous convolution layer step\n",
        "5. After applying all those convolution layers, I need to flatten the data so that it can be passed into the next layers so that the network can be narrowed down into categorizing the image into one of the 10 number categories\n",
        "6. I apply a dropout function with 25% probability of dropping to reduce overfitting between the layers\n",
        "7. The dense layer that comes up next condenses the data into the size of 100 using the ReLu activation function\n",
        "8. The last layer, another dense layer, condenses the data into the size of 10 using the SoftMax activation function so that images can categorized into one of the ten numbers (0 to 9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocEZAD8MBi_J",
        "outputId": "623256bc-0b94-470b-b747-25ae4d4a3ff8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 8, 8, 64)          51264     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               102500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 155,606\n",
            "Trainable params: 155,606\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_6_t6SlBoOQ"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\n",
        "             optimizer = 'adam',\n",
        "             metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNWcqdNjK3Q_"
      },
      "source": [
        "Here, I am utilizing a categorical cross entropy loss function to have a better understand how well this convolutional neural network performed the task of digit recognition. I used cross entropy since I am dealing with a multi class classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEs2JC2cBs7o"
      },
      "source": [
        "# Keras is expecting 4 dimensions so this will expand the dimensions\n",
        "# categorizing the data into the 10 numbers in the dataset\n",
        "train_X_Inflated = np.expand_dims(train_X, axis = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIojpIi7MDGg"
      },
      "source": [
        "Before being able to fit the training data to our model, I needed to expand the dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xjhkNTmDHVP",
        "outputId": "4dbcecb7-5f5d-4c01-c318-8c37e31c0fc8"
      },
      "source": [
        "# fitting the CNN model to our training data\n",
        "model.fit(train_X_Inflated, train_y_matrix, epochs = 10, batch_size = 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "60/60 [==============================] - 12s 40ms/step - loss: 3.7458 - accuracy: 0.6205\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.2958 - accuracy: 0.9098\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.1738 - accuracy: 0.9468\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.1291 - accuracy: 0.9602\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.1035 - accuracy: 0.9681\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0889 - accuracy: 0.9725\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0776 - accuracy: 0.9759\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0706 - accuracy: 0.9776\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0632 - accuracy: 0.9795\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0580 - accuracy: 0.9819\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f98308f74d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVDLmn-WbcOT"
      },
      "source": [
        "I fitted the training data to the convolutional neural network in this step. I included 10 epochs, which is running the entire model over the training data 10 times to increase the end accuracy of the model. I included a batch size of 1000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vd2_EC_De6s"
      },
      "source": [
        "# Keras is expecting 4 dimensions so this will expand the dimensions\n",
        "test_X_inflated = np.expand_dims(test_X, axis = 3)\n",
        "test_y_matrix = to_categorical(test_y, num_classes = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "998XMY34cpZG"
      },
      "source": [
        "In this step, I expanded the dimensions of the test set x and updated the test set y to one-hot categorical. These are the necessary conversions required to run them through the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv3AWGb6H67J",
        "outputId": "5c912882-9468-4abe-9574-c433a461e520"
      },
      "source": [
        "# gathering the predictions\n",
        "predict_x=model.predict(test_X_inflated) \n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "\n",
        "print(\"y_train shape: {}\".format(np.shape(train_y_matrix)))\n",
        "print(\"x_train shape: {}\".format(np.shape(train_X_Inflated)))\n",
        "\n",
        "print(\"y_test shape: {}\".format(np.shape(test_y_matrix)))\n",
        "print(\"x_test shape: {}\".format(np.shape(test_X_inflated)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape: (60000, 10)\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "y_test shape: (10000, 10)\n",
            "x_test shape: (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rRawurbc4Nv"
      },
      "source": [
        "In this step I made the predictions by utilizing the inflated test x set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5bhOGKFIxfb",
        "outputId": "8b84288d-ca6d-4e98-a231-eeae847f488c"
      },
      "source": [
        "# evaluate the accuracy and loss of the CNN model\n",
        "evaluate = model.evaluate(test_X_inflated, test_y_matrix)\n",
        "print(\"Loss: {}\".format(evaluate[0]))\n",
        "print(\"Accuracy: {}\".format(evaluate[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0368 - accuracy: 0.9871\n",
            "Loss: 0.0368431992828846\n",
            "Accuracy: 0.9871000051498413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apxi3_xodB06"
      },
      "source": [
        "By using the evaluation function of model, I found the accuracy to be 98.98% accurate. There was a loss of 0.03968."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2sCdOp6JT8Q"
      },
      "source": [
        "### Comparing Results to Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qeEC-WuJTb4",
        "outputId": "c0d70371-f1c7-4618-f261-005d6eb41039"
      },
      "source": [
        "print(classes_x)\n",
        "tempList = []\n",
        "\n",
        "#this loop iterates through y_test and converts a format so we can compare to our predictions\n",
        "for row in test_y_matrix:\n",
        "    tempClass = np.argmax(row)\n",
        "    tempList.append(tempClass)\n",
        "\n",
        "\n",
        "test_y_Classes = np.array(tempList)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 2 1 ... 4 5 6]\n",
            "[7 2 1 ... 4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKk2-DhFdRli"
      },
      "source": [
        "I converted the test y set so it can be compared to the predictions I made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i1Rl2SUJiP3"
      },
      "source": [
        "wrongPredictionIndices = []\n",
        "i = 0\n",
        "\n",
        "for actual, prediction in zip(test_y_Classes, classes_x):\n",
        "    if actual != prediction:\n",
        "        wrongPredictionIndices.append(i)\n",
        "    i = i + 1\n",
        "\n",
        "# these are the ten of indices of all the wrong predictions done by CNN\n",
        "wrongPredictionIndices[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrOtL8qqdij5"
      },
      "source": [
        "I collected all the indices of the wrongfully made predictions and presented them in the format of the array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl_5pyl9uELd"
      },
      "source": [
        "**Accuracy Table**\n",
        "\n",
        "|Model | Accuracy |\n",
        "|------|----------|\n",
        "|**KNN**   | 96.65% |\n",
        "|**SVM**   | 93.76% |\n",
        "|**CNN**   | 98.88% |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlNUezEsLe1z"
      },
      "source": [
        "# Conclusion\n",
        "Of the three models we built for the MNIST dataset (KNN, SVM, and CNN), CNN had the highest accuracy at 98.9%. In addition, while SVM was very slow to complete and runs ever slower as dataset size increases, CNN was quick to execute. KNN was similar in speed but had a slightly lower accuracy. Therefore, the model that performed the best on this dataset was CNN.\n",
        "\n",
        "A real world application of our project could be used for a site like Ancestry.com. By applying our project to this site, individuals could upload old family documents to the database to help assist them in researching their own family tree. However, this is only the tip of the iceberg - there are many handwritten documents that have yet to be digitized. Once they are, they will be available to the public, and computers can scan them and recommend potentially useful information to users. In the era of big data, the need for more data is ever increasing. By providing this new source of digitized data, greater predictions could be made in multitudes of applications like in insurance policies or even zoning decisions made by local governments. Digitizing documents is currently a slow process. It is currently done mostly by hand where the document is manually read and typed out, but progress can become much more efficient with reliable script to text algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb6aP8sYRv-b"
      },
      "source": [
        "## Next Steps\n",
        "By recognizing particular numbers, we can scale this algorithm to recognize letters as well. The ability to classify both numbers and letters would allow us to develop a computer algorithm that would accurately digitize handwritten documents and find meaningful insights from them. We would also continue to expand our search in terms of the best models to be used for actual practical application. Additionally, the search for more data sets will be part of our next steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0h7OkApQtcZ"
      },
      "source": [
        "## Future Research\n",
        "For future research, it would be valuable to include other metrics to compare models by. Another important area of research would be expanding the dataset to include letters. If research in script to text algorithms is desired, expanding the dataset would allow us to determine which algorithm is best for classifying letters. Having datasets in other languages would also be another large area of research in the field of linguistics. As is apparent by the diversity of applications that we have discussed so far, our project can be applied to a variety of areas of research."
      ]
    }
  ]
}